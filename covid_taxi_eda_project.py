# -*- coding: utf-8 -*-
"""covid_taxi_EDA_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bSVhWL3J9FX5uw35DdNxiPUj2Tu747rW

# INTRODUCTION

# Study the impact of Covid-19 lockdown on New York Taxi Market for 'Fast Cars'  <br>

## INTRODUCTION<br>

We are working as a data analyst in a company called Fast Cars. Fast Cars is a cab agglomerator like Uber and Ola i.e. it connects passengers to cabs in cities for travel through an app.

They are going to launch their product in New York City. But before they want to understand the new york taxi market.

As a data analyst what we want to analyse is how the covid-19 lockdown has affected the New York taxi market and give our insights based on which Company Fast Cars can launch its services.
We have Yellow Taxi dataset for the month of February 2020 -just befor lockdown and for the month of July 2020 -just after lockdown
"""

from google.colab import drive
drive.mount('/content/drive')

"""## DATA IMPORT AND BASIC OBSERVATIONS"""

# import important libraries - matplotlib, seaborn and pandas
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

"""# **FEBRUARY 2020 - PRE-COVID LOCKDOWN ANALYSIS**"""

file_loc ='/content/drive/MyDrive/One_Learn_Data_Analytics_Module/taxi_data/yellow_tripdata_2020-02.csv'

# read file
trip_data = pd.read_csv(file_loc)
# print data shape
print(trip_data.shape)
# print data head
trip_data.head()

# print data tail
trip_data.tail()

# print data info
trip_data.info()

"""By looking at data_description file we find that following columns would be useful for our analysis:(you can find the data description file here - https://drive.google.com/file/d/1B6JUAqGNmaMfyc6TQqxRWrvOVI1DtgQf/view?usp=sharing)<br>
* tpep_pickup_datetime - The date and time when the meter was engaged. 
* tpep_dropoff_datetime - The date and time when the meter was disengaged.
* Passenger_count - The number of passengers in the vehicle. 
* Trip_distance - The elapsed trip distance in miles reported by the taximeter.
* PULocationID - TLC Taxi Zone in which the taximeter was engaged
* DOLocationID - TLC Taxi Zone in which the taximeter was disengaged
* Payment_type - A numeric code signifying how the passenger paid for the trip. 
* Fare_amount - The time-and-distance fare calculated by the meter.
* Extra - Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges.
* MTA_tax - \\$ 0.50 MTA tax that is automatically triggered based on the metered rate in use.
* Improvement_surcharge - \\$0.30 improvement surcharge assessed trips at the flag drop. The improvement surcharge began being levied in 2015.
* congestion_surcharge - fees on congestion
* Tip_amount - This field is automatically populated for credit card tips. Cash tips are not included.
* Tolls_amount - Total amount of all tolls paid in trip.
* Total_amount -  The total amount charged to passengers. Does not include cash tips.

And we will drop the following columns:<br>
* VendorID
* RateCodeID 
* Store_and_fwd_flag

## DATA MANIPULATION BEFORE EDA
"""

# remove following columns - 'VendorID','RatecodeID','store_and_fwd_flag'
trip_data.drop(['VendorID','RatecodeID','store_and_fwd_flag'],axis=1,inplace=True)
# print data head
trip_data.head()

"""We will now deal with time related columns, we have two time related columns
* tpep_pickup_datetime 
* tpep_dropoff_datetime

We will first convert these column to datatime data type of pandas.

we will create three different features from these  
* hour - pickup hour and dropoff hour
* day name - this is basically the day of the week when trip took place - we will only take day name from pickup date.
( as day name for drop date is supposed to be same as pickup date)
* duration of trip
"""

# convert 'tpep_pickup_datetime' and 'tpep_dropoff_datetime' to datetime format
trip_data['tpep_pickup_datetime'] = pd.to_datetime(trip_data['tpep_pickup_datetime'])
trip_data['tpep_dropoff_datetime'] = pd.to_datetime(trip_data['tpep_dropoff_datetime'])
# print data info
print(trip_data.info())
# print data head
trip_data.head()

# create 'duration' column using pd.Timedelta(minutes=1)
trip_data['duration'] = (trip_data['tpep_dropoff_datetime'] - trip_data['tpep_pickup_datetime'])/ pd.Timedelta(minutes=1)
# create 'trip_pickup_hour' column using 'tpep_pickup_datetime' column
trip_data['trip_pickup_hour'] = trip_data['tpep_pickup_datetime'].dt.hour
# create 'trip_dropoff_hour' column using 'tpep_dropoff_datetime' column
trip_data['trip_dropoff_hour'] = trip_data['tpep_dropoff_datetime'].dt.hour
# create 'trip_day' column using 'tpep_pickup_datetime' column - use day_name()
trip_data['trip_day'] = trip_data['tpep_pickup_datetime'].dt.day_name()
# print data info
print(trip_data.info())
# print data head
trip_data.head()

"""Let's also see the number of missing values for each column

axis= 0 ---> across rows - the result will come for each columns

axis = 1 ---> across columns - the result will come for each row
"""

# print missing values for each column - use .isnull().sum
trip_data.isnull().sum(axis=0).reset_index()

"""From the above table we can observe that we have no missing values.

For payment_type we have the following mapping for categories:<br>
1= Credit card
2= Cash
3= No charge
4= Dispute
5= Unknown
6= Voided trip

let's just check if we have only these categories available in payment_type or not
"""

# value_counts for 'payment_type' column
trip_data['payment_type'].value_counts()

"""Now we will replace these number in payment category with actual category names."""

# function for mapping numerical payment_type to actual payment
def map_payment_type(x):
    if x==1:
        return 'Credit_card'
    elif x==2:
        return 'Cash'
    elif x==3:
        return 'No_charge'
    elif x==4:
        return 'Dispute'
    elif x==5:
        return 'Unknown'
    else:
        return 'Voided_trip'

# use .apply and lambda on payment_type column to change 'payment_type' column
trip_data['payment_type'] = trip_data.payment_type.apply(lambda x:map_payment_type(x))
# print data head
trip_data.head()

# print data info to show that payment_type data type has changed
trip_data.info()

"""Now our Total_amount is basically<br>
Total_amount = fare_amount + tolls_amount + tip_amount + (extra + mta_tax + improvement_surcharge)

of the above components of total_amount we will specifically focus on 'fare_amount','tip_amount', 'tolls_amount' and 'total taxes'.

We are combining the extra, mta_tax and improvement_surcharge under one category called total_taxes as these are determined by local laws and taxes and is not dependent upon distance travelled or time taken for trip.

Here total taxes would be the sum of three columns 'extra','mta_tax', 'improvement_surcharge'. So we will make a new column for total_taxes.

We will also drop these three columns 'extra','mta_tax','improvement_surcharge'.

"""

# create 'total_taxes' column from summing 'extra','mta_tax', 'improvement_surcharge'
trip_data['total_taxes'] = trip_data['extra']+trip_data['mta_tax']+trip_data['improvement_surcharge']
# drop 'extra','mta_tax','improvement_surcharge' columns
trip_data.drop(['extra','mta_tax','improvement_surcharge'],axis=1,inplace=True)
# print data head
trip_data.head()

trip_data.head()

"""## ASSUMPTIONS/ANALYSIS THAT MIGHT BE USEFUL FOR OUR COMPANY<br>

**IMPORTANT CHARACTERISTICS OF A TRIP**
* fare_amount, trip_distance, duration and passenger count distribution can tell us about the important characteristics about the trip.


**PRICING EXPLORATION**
* payment_type can tell us which kind of payment mode the customer usually favours.


* Another issue that taxi companies face is pricing the trip appropriately. So for exploring the pricing of trip, we can also look into the relationship between pricing related variables and hour/day of trip and pricing related variables and location.

**TIME/LOCATION EXPLORATION** 
* To maximize the earnings we should be focussing on trips which are on busy locations and busy times. 


**DURATION OF TRIP EXPLORATION**
* A typical taxi company faces a common problem of efficiently assigning the cabs to passengers so that the service is smooth and hassle free. One of main issue is determining the duration of the current trip. So, We should look into relationship between duration and location, duration and hour of trip.

There are multiple ways to approach an exploratory data analytics problems. Below we are mentioning two prominent ways. (In both of the approaches at the back of the mind, we should be trying to assess if the analysis we are doing is helping in solving our initial case study problem):     
1. Question based analysis (it can be univariate or bivariate depending upon the question). Finally write the answers to each of the questions for each of the analysis.
2. Doing first the univariate and secondly bivariate analysis and then join the insights from both of them to get final analysis.

## DATA ANALYSIS<br>

**UNIVARIATE ANALYSIS**<br>
The first step in doing any kind of EDA is identifying the distribution of important variables in EDA. This helps us in finding important insights about the data.<br>
We should look into the distribution of these specific columns:<br>
Price Based Columns
* fare_amount
* tip_amount
* total_taxes
* tolls_amount
* payment_type
* total_amount

Time Based Columns
* duration
* trip_pickup_hour
* trip_dropoff_hour
* trip_day

Distance/Location Based Columns
* trip_distance
* PULocationID
* DOLocationID

Other columns
* passenger_count

Before we explore the distribution of each column we must identify column category because distribution analysis depends upon variable category:<br>
* Continuous - column which are measurable and uncountable in nature - we use histograms and box plot
* Categorical - column which have categories as it data - we use bar charts

Following columns are continuous in nature:<br>
* fare_amount
* tip_amount
* total_taxes
* total_amount
* duration
* trip_distance
* tolls_amount

Following columns are categorical in nature:<br>
* payment_type
* trip_pickup_hour - it has 24 categories
* trip_dropoff_hour - it has 24 categories
* trip_day - it has 7 categories
* PULocationID
* DOLocationID
* Passenger_count

We will look into the distrbution of passenger_count at the last.

**CONTINUOUS VARIABLE DISTRIBUTION**
"""

# continuous_columns list
continuous_columns = ['fare_amount','tip_amount','total_taxes','total_amount','duration','trip_distance','tolls_amount']

trip_data[continuous_columns].head()

# use .describe() for showing the statistics for continuous columns
trip_data[continuous_columns].describe()

# import gridspec function from matplotlib
from matplotlib import gridspec

# for loop for continuous_columns variable
for feature in continuous_columns:
    # create a figure object using plt.figure
    fig = plt.figure(figsize=(14,7))
    # use gridspec.GridSpect with arguments nrows, ncols and figure to create areas for 2 plots in figure object
    gs = gridspec.GridSpec(nrows=1, ncols=2, figure=fig)
    # ax1 is first axes object created using fig.add_subplot(gs[0,0]) - controls the first area of figure object
    ax1 = fig.add_subplot(gs[0, 0])
    # histogram plot in first area using sns.distplot - attributes are kde and ax
    sns.distplot(trip_data[feature],kde=True,ax=ax1)
    # using ax1.set_title to create title for histograms
    ax1.set_title('histogram of column values in '+feature)
    # ax2 is second axes object created using fig.add_subplot(gs[0,1]) - controls the second area of figure object
    ax2 = fig.add_subplot(gs[0,1])
    # box plot  in second area using sns.boxplot - attributes are ax
    sns.boxplot(trip_data[feature],ax=ax2)
    # using ax2.set_title for box plot
    ax2.set_title('box plot of column values in '+feature)
    # seaborn style setting
    sns.set()
    # matplotlib command for displaying plots
    plt.show()

"""Negtive values for columns does not make sense<br>
fare_amount<br>
tip_amount<br>
total_taxes<br>
tolls_amount<br>
total_amount<br>
duration<br>

Let's just observe how the negative values in each of these columns look like
"""

# using .loc to show negative values in fare_amount  # 8 mil rows
trip_data.loc[trip_data['fare_amount']<0]

# using .loc to show negative values in tip_amount
trip_data.loc[trip_data['tip_amount']<0]

# using .loc to show negative values in tolls_amount
trip_data.loc[trip_data['tolls_amount']<0]

# using .loc to show negative values in total_taxes
trip_data.loc[trip_data['total_taxes']<0]

# using .loc to show negative values in total_amount
trip_data.loc[trip_data['total_amount']<0]

"""Can i replace negative values of fare_amount with 0?

Ans. Not here. Because it will not give us a good measure of averages or other statistical measures.

From the above table displays it is clear whenever fare_amount is negative, we have negative values in 'tip_amount','total_taxes' and 'total_amount'. Negative values for these cases does not make sense for doing our analysis. The reason for these negative values can be explored later on if we want to understand the data more better. For now we will remove these rows. 

Also, number of negative rows are 20007 which is 0.31% of 6299354 total  observations. So even if we remove them it does not hamper the quantity of data that we have.
"""

# data shape before filtering negative fare_amount rows
print(trip_data.shape)
# using .loc to filter only those rows where fare_amount is positive 
trip_data = trip_data.loc[trip_data['fare_amount']>=0]
# print data shape
print(trip_data.shape)
# print data.head()
trip_data.head()

print(trip_data.loc[trip_data['tip_amount']<0].shape)
print(trip_data.loc[trip_data['total_taxes']<0].shape)

"""We will look into the negative values for duration"""

# using .loc to show negative values in duration
trip_data.loc[trip_data['duration']<0]
trip_data.loc[trip_data['duration']<0].shape

"""Since there are only thirty two rows with negative duration, we will remove them so as to do our analysis in a better way"""

# using .loc to filter only those rows where duration is positive 
trip_data = trip_data.loc[trip_data['duration']>=0]
print(trip_data.shape)

"""Now we will again look at the distribution plots for these variables"""

# import gridspec function from matplotlib
from matplotlib import gridspec
# plot box plot and histograms for continuous_columns variables
for feature in continuous_columns:
    fig = plt.figure(figsize=(14,7))
    gs = gridspec.GridSpec(nrows=1, ncols=2, figure=fig)
    ax1 = fig.add_subplot(gs[0, 0])
    sns.distplot(trip_data[feature],kde=True,ax=ax1)
    ax1.set_title('histogram of column values in '+feature)
    ax2 = fig.add_subplot(gs[0,1])
    sns.boxplot(trip_data[feature],ax=ax2)
    ax2.set_title('box plot of column values in '+feature)
    sns.set()
    plt.show()

# use .describe() again to show the statistics for these continuous variables
trip_data[continuous_columns].describe()

"""Looking from the above histograms we can decipher following information for each column <br>
* fare_amount  - most of the fare amount is within 10 dollar value as is shown by the median value. Though there are some significant outliers, the maximum of which is 6000 dollars.


* tip_amount - most of the tip amount is within 1-2 dollar as is shown by the median value. Though again here too we have outliers, the maximum of which is around 550 dollars. 


* tolls_amount - most of the tolls_amount value is 0 so it seems most of the trips do not have to pay for tolls.


* total_taxes - most of the total_taxes values is within 1.3 dollars as is shown by the median value. Though we have outliers in this case but it is not as signiificant as the case for tip and fare.


* total_amount - most of the total_amount values is within 14 dollars as is shown by the median value. Again the outliers in this case seems mostly because of outliers in fare_amount.


* duration - most of the values in duration is within 10 minutes range as is shown by the median value. We do have some outliers which are beyond the range of 3000 minutes.


* trip_distance - most of the trip_distance is within 1.6 miles value as is shown by the median. The outlier in this case is quite less.

**CATEGORICAL VARIABLE DISTRIBUTION**<br>
Let's move on to analyse the distribution of categorical variables

for analysing distribution of categorical variables we use bar plots showing the count% of each category.
"""

# list of categorical_variables
categorical_variables = ['payment_type','trip_pickup_hour','trip_dropoff_hour','trip_day','PULocationID','DOLocationID']

# start exploration with payment_type using .value_counts()
trip_data['payment_type'].value_counts()

# but this is a series for ease of plotting we need to use dataframe using .reset_index() on value_counts()
payment_type_category_count = trip_data['payment_type'].value_counts().reset_index()
# print the above dataframe
payment_type_category_count

# we are shown the count under each category but it is better to have count% for comparison - create count_percent col
payment_type_category_count['count_percent'] = (payment_type_category_count['payment_type']/trip_data.shape[0])*100
# print the data frame
payment_type_category_count

# now let's plot it as bar chart
# first step - create fig, ax object using plt.subplots
fig,ax = plt.subplots(figsize=(7,7))
# second step - use sns.barplot(x, y , data, ax) for plotting bar plot
sns.barplot(x = 'index', y = 'count_percent', data=payment_type_category_count,ax=ax)
# third step - use ax object to change plot properties - here we set a title with ax.set_title()
ax.set_title('box plot for payment_type column')
# third step - seaborn style setting
sns.set()
# fourth step - use plt.show() for showing the plots
plt.show()

"""From above we can understand that most of the payments are done through cash and credit cards. The proportion of credit card payments is over 70%.

Now we look into time based categorical variables.<br>
* 'trip_pickup_hour'
* 'trip_dropoff_hour'
* 'trip_day'

"""

# now let's plot all the time based categorical variables in this way using a for loop
for feature in ['trip_pickup_hour','trip_dropoff_hour','trip_day']:
    # Create a dataframe for each of the feature using value_counts().reset_index()
    feature_value_counts = trip_data[feature].value_counts().reset_index()
    # create count_percent column 
    feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data.shape[0])*100
    # print the number of categories in the feature
    print('Number of categories in feature '+ feature + ' is ' + str(feature_value_counts.shape[0]))
    # Create fig,ax object using plt.subplots 
    if feature_value_counts.shape[0]<10:
        fig,ax = plt.subplots(figsize=(7,7))
    else:
        fig,ax = plt.subplots(figsize=(20,7))
    # plot barplot x='index' and y='count_percent' using sns.barplot
    sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
    # set_title
    ax.set_title('Bar plot for '+ feature)
    # set_xlabel
    ax.set_xlabel(feature)
    sns.set()
    plt.show()

"""Based on above plots we can observe following things
* Trip Hour 
    * the dropoff and pick up hour distribution looks almost same, it is because the trip duration in most of the cases is less than an hour with the median duration value as 10 min. 
    * Peak hour for the pick up and drop off is around evening from 5 to 8. The busiest time is 6PM.
    * there is less traffic during night times and only after 8AM in morning does the pickup and drop off starts picking up pace.
* Trip day
    * Sunday has the lowest taxi uses.
    * Weekdays except Monday have heavy taxi uses.
    * Among weekends Saturday has taxi uses more than on the  weekdays.

**READ THE ANALYSIS OF LOCATION ON YOUR OWN**

Moving on we will explore the distribution of location based features:<br>
* 'PULocationID'
* 'DOLocationID'
"""

# let's see the number of categories available in both pickup and dropoff location - PULocationID and DOLocationID
print(trip_data['PULocationID'].value_counts().shape)
print(trip_data['DOLocationID'].value_counts().shape)

"""So we have around 260 categories for location. To plot it on bar plots we need to increase the figure size.

"""

for feature in ['PULocationID','DOLocationID']:
    # Create a dataframe for the feature using value_counts().reset_index()
    feature_value_counts = trip_data[feature].value_counts().reset_index()
    # create count_percent column 
    feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data.shape[0])*100
    # print the number of categories in the feature
    print('Number of categories in feature '+ feature + ' is ' + str(feature_value_counts.shape[0]))
    # Create fig,ax object using plt.subplots 
    fig,ax = plt.subplots(figsize=(25,7))
    # plot barplot x='index' and y='count_percent' using sns.barplot
    sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
    # set_title
    ax.set_title('Bar plot for '+ feature)
    # set_xlabel
    ax.set_xlabel(feature)
    sns.set()
    plt.show()

"""The above plots looks quite messy but one insight that we can indetify from above plot that most of pickup and dropoff points do not have more 0.5% traffic (0.5 percent of 6279315 total trips is 31397) it means most of the location Ids have lower count percentage out of total IDs which means that only at some locations cabs are frequently required.

So in our next plot we will filter out these pickup and dropoff points to look into the graph more clearly.
"""

for feature in ['PULocationID','DOLocationID']:
    feature_value_counts = trip_data[feature].value_counts().reset_index()
    feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data.shape[0])*100
    # filter only those location which has more than 0.5 % of traffic
    feature_value_counts = feature_value_counts.loc[feature_value_counts['count_percent']>=0.5]
    print('Number of categories in feature '+ feature + ' above 0.5 % count is ' + str(feature_value_counts.shape[0]))
    fig,ax = plt.subplots(figsize=(25,7))
    sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
    ax.set_title('Bar plot for '+ feature)
    ax.set_xlabel(feature)
    sns.set()
    plt.show()

"""From the above plots we can glance following insights<br>
* The busiest location in terms of pickup are 161, 236 and 237
* The busiest location for dropoff too are 161, 236 and 237.

We can also look for routes which are busiest. 

For exploring busy routes we need to create a new route column which is a combination of pickup and dropoff point.

So route = 'PULocationID'-'DULocationID'
"""

# create routes column using PULocationID and DOLocationID with lambda function
trip_data['routes'] = trip_data.apply(lambda x: str(x['PULocationID'])+'-'+str(x['DOLocationID']),axis=1)

# print the first five rows of routes data
trip_data['routes'].head()

trip_data.head()

"""Now let's explore routes through the same bar plot code that we used for Location ID's. But in this case we will only look for routes with more than 0.25% counts (21889 trips)."""

# plot bar plot for routes which have trip count above 0.25%
feature = 'routes'
feature_value_counts = trip_data[feature].value_counts().reset_index()
feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data.shape[0])*100
# choosing routes where the trip percent is above 0.25% of total trips
feature_value_counts = feature_value_counts.loc[feature_value_counts['count_percent']>=0.25]
print('Number of categories in feature '+ feature + ' above 0.25 % count is ' + str(feature_value_counts.shape[0]))
fig,ax = plt.subplots(figsize=(25,7))
sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
ax.set_title('Bar plot for '+ feature)
ax.set_xlabel(feature)
sns.set()
plt.show()

"""From the above plot we can observe that 5 busiest route are following:<br>
237-236<br>
236-236<br>
236-237<br>
237-237<br>
264-264<br>

Finally we will look into the distribution of passenger_count
"""

# look into value_counts of 'passenger_count'
trip_data['passenger_count'].value_counts()

"""Here we see that the mostly 1 or 2 passengers avail the cab. The instance of large group of people travelling together is rare.

This is the result of some of the most important insights after doing univariate analysis:<br>
* fare_amount  - most of the fare amount is within 10 dollar value as is shown by the median value. Though there are some significant outliers, the maximum of which is 6000 dollars.


* tip_amount - most of the tip amount is within 1-2 dollar as is shown by the median value. Though again here too we have outliers, the maximum of which is around 550 dollars. 


* duration - most of the values in duration is within 10 minutes range as is shown by the median value. We do have some outliers which are beyond the range of 3000 minutes.


* trip_distance - most of the trip_distance is within 1.6 miles value as is shown by the median. The outlier in this case is quite less.


* Credit card is the most preferred mode of payment followed by cash.


* Peak hour for the pick up and drop off is around evening from 5 to 8. The busiest time is 6PM.


* Weekdays except monday have heavy taxi uses and among weekends Saturday has taxi uses more than the weekdays.


* The busiest location in terms of pickup and dropoff are 161, 236 and 237.


* Four of the busiest routes are -237-236, 236-236, 236-237,237-237


* Mostly 1 or 2 passenger avail the cab. Group rides are less common.

**BIVARIATE ANALYSIS**<br>
Remember that we made some analysis points regarding exploration of duration and pricing:<br>

For pricing we will be exploring it's relationship with:<br>
* hour/day of trip 
* pickup location of trip

For duration we will be exploring it's relationship with:<br>
* hour of day 
* pickup location of trip

**PRICING EXPLORATION**

We have following variables in the dataset that is associated with pricing:<br>
* fare_amount
* tip_amount
* total_taxes
* tolls_amount
* total_amount

In our anlaysis for now we will be focussing on:<br>
* fare_amount
* tip_amount
* total_taxes
* total_amount

we are leaving tolls_amount for now from our analysis as it contributes very little to the total_amount value because it's median value was 0 i.e. most of the trips are not paying tolls_amount.


*** PRICING VARIABLE EXPLORATION WITH HOUR/DAY OF TRIP ***<br>
All of our pricing variables are continuous and Hour/Day is categorical.

The way to explore relationship between a continuous variable and categorical variable is through a box plot. We create box plot for each category of categorical variable so as to see how the distribution changes for the continuous variables as the category values changes for categorical variable.

We will start with fare_amount exploration.

Let's do a box plot of fair_amount with hour/day of trip to see how the fare changes for different hours of the day and for different days of the week
"""

# fig,ax object using plt.subplots()
fig,ax = plt.subplots(figsize=(25,7))
# box plot using - sns.boxplot(x, y , data, ax)
sns.boxplot(x = 'trip_pickup_hour',y='fare_amount',data=trip_data,ax=ax)
# ax.set_title
ax.set_title('box plot of fare_amount wrt hour of the day')
# seaborn style setting
sns.set()
# matplotlib plt.show()
plt.show()

# fig,ax object using plt.subplots()
fig,ax = plt.subplots(figsize=(25,7))
# box plot using - sns.boxplot(x, y , data, ax)
sns.boxplot(x = 'trip_dropoff_hour',y='fare_amount',data=trip_data,ax=ax)
# ax.set_title
ax.set_title('box plot of fare_amount wrt hour of the day')
# seaborn style setting
sns.set()
# matplotlib plt.show()
plt.show()

"""From the above plot we can observe that some of the largest outliers in fare happens during 14 or 2PM to 18 or 6PM based on pickup time while some in the morning hours.

Based on dropoff time, we have heavy outliers from 3 p.m. to 7 p.m. and  some in the morning similar to pickup time.

For observing the distribution in a better way we would restrict the fare_amount to below 50 dollars. 
"""

trip_data = trip_data.loc[trip_data['fare']]

# restricted_fare_amount_data dataframe formation by filtering fare_amount less than 50 dollars
restricted_fare_amount_data = trip_data.loc[(trip_data['fare_amount']<=50) & (trip_data['fare_amount']>=0)]
restricted_fare_amount_data.shape

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='fare_amount',data=restricted_fare_amount_data,ax=ax)
ax.set_title('box plot of fare_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='fare_amount',data=restricted_fare_amount_data,ax=ax)
ax.set_title('box plot of fare_amount wrt hour of the day')
sns.set()
plt.show()

"""We can see from the plots that trip pickup and dropoff hours do not have much affect on median fare_amount as median is almost same for all the hours.

let's us see if hour of day has any effect on other pricing related variables or not.

Starting with total_amount
"""

fig,ax = plt.subplots(figsize=(25,7))
# sns.boxplot changes
sns.boxplot(x = 'trip_pickup_hour',y='total_amount',data=trip_data,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
# sns.boxplot changes
sns.boxplot(x = 'trip_dropoff_hour',y='total_amount',data=trip_data,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

"""Again here since we are plotting full range of total_amount our graph is able to show heavy outliers prominently but not the distribution of general cases.

So we will again build a dataframe for total_amount with restricted values less than 50 dollars
"""

# restricted_total_amount_data for filtering total_amount data to less than 50 dollars
restricted_total_amount_data = trip_data.loc[trip_data['total_amount']<=50]
restricted_total_amount_data.shape

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='total_amount',data=restricted_total_amount_data,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='total_amount',data=restricted_total_amount_data,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

"""Again we can see the median value does not changes much for each hour though there is variability in price across the hours indicated by different sizes of boxes for different hours.

We will explore tip_amount and total_taxes now. But for exploring them we will retrict the values for these variables to below 10 dollars because the median value for tip_amount was around 1-2 dollars while for total_taxes was around 1.3 dollars so if to see the general distribution clearly we are restricting it to a range of 5 times the median value.
"""

restricted_tip_amount_data = trip_data.loc[trip_data['tip_amount']<10]
restricted_total_taxes_data = trip_data.loc[trip_data['total_taxes']<10]

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='tip_amount',data=restricted_tip_amount_data,ax=ax)
ax.set_title('box plot of tip_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='tip_amount',data=restricted_tip_amount_data,ax=ax)
ax.set_title('box plot of tip_amount wrt hour of the day')
sns.set()
plt.show()

"""Based on tip_amount plot we can see that tip_amount too does not vary much based on hours.

Let's observe total_taxes now
"""

# total_taxes = extra + improvement_surcharges + Mta

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='total_taxes',data=restricted_total_taxes_data,ax=ax)
ax.set_title('box plot of total_taxes wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='total_taxes',data=restricted_total_taxes_data,ax=ax)
ax.set_title('box plot of total_taxes wrt hour of the day')
sns.set()
plt.show()

"""Now in this plot we can clearly observe that total_taxes change significantly with hour of the day. There are two patterns that we can observe here:<br>
* from the hour 8PM to 5AM the median taxes seem to be a bit higher than other hours, it may be due to some overnight surcharges.
* Evening from 5PM to 7PM have quite variable taxes and is a bit higher than other times, it may be due to higher traffic charges.

Overall the effect of hour of day is most clearly visible on total_taxes. we have two insights about how taxes change with hours
* Overnight charges are applied between 8PM to 5AM
* Evening has higher variability in taxes and the taxes are usually high.

Let's move and explore the distribution of pricing variables with respect to day of week. For this analysis we will be using restricited version of dataset that we built for fare_amount, total_amount, tip_amount and total_taxes.
"""

# plot of trip_day with fare_amount
fig,ax = plt.subplots(figsize=(7,7))
# changes in sns.boxplot x and y
sns.boxplot(x = 'trip_day',y='fare_amount',data=restricted_fare_amount_data,ax=ax)
ax.set_title('box plot of fare_amount wrt the day of the week')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(7,7))
sns.boxplot(x = 'trip_day',y='total_amount',data=restricted_total_amount_data,ax=ax)
ax.set_title('box plot of total_amount wrt the day of the week')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(7,7))
sns.boxplot(x = 'trip_day',y='tip_amount',data=restricted_tip_amount_data,ax=ax)
ax.set_title('box plot of tip_amount wrt the day of the week')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(7,7))
sns.boxplot(x = 'trip_day',y='total_taxes',data=restricted_total_taxes_data,ax=ax)
ax.set_title('box plot of total_taxes wrt the day of the week')
sns.set()
plt.show()

"""We can see that pricing overall does not change much with respect to day of week.

*** PRICING VARIABLE EXPLORATION WITH LOCATION OF TRIP ***<br>

Here we will look into the price changes for the most frequent trip pickup locations.
"""

# create a new series using value_counts() on 'PULocationID'
pickup_location_value_counts = trip_data['PULocationID'].value_counts()
# show the series
pickup_location_value_counts.head()

# top 10 frequent pickup locations using .nlargest(10).index
top_10_frequent_pickup_locations = pickup_location_value_counts.nlargest(10).index
top_10_frequent_pickup_locations

# for loop for plotting box plot of each of the top 10 frequent pickup locations
for top_pickup_locID in top_10_frequent_pickup_locations:
    # create the new dataframe for each location using .loc on 'PULocationID' - pickup_locID_dataframe
    pickup_locID_dataframe = trip_data.loc[trip_data['PULocationID'] == top_pickup_locID]
    # print the median fare_amount for the top_pickup_locID
    print('The median fare_amount of trips taken from '+str(top_pickup_locID)+' is '+str(pickup_locID_dataframe['fare_amount'].median()))
    # fig,ax object
    fig,ax = plt.subplots(figsize=(6,6))
    # sns.boxplot of fare_amount from the dataframe pickup_locID_dataframe
    sns.boxplot(pickup_locID_dataframe['fare_amount'],ax=ax)
    # set_title
    ax.set_title('box plot of fare_amount for pickup location '+ str(top_pickup_locID))
    sns.set()
    plt.show()

"""So from above plot we can observe that for one of the most busiest pickup location median fare_amount is quite low in comparison to other busy locations. Though the outliers for pickup location 48 is high.

This could be helpful in adjusting our revenue expectation based on putting our cabs in a given location because just choosing busy pickup locations for higher revenue won't work, we may have to choose locations taking into consideration both busy traffic and higher median fare_amount.

**DURATION EXPLORATION**

Here we will explore the duration of trip exploration with pickup hour of day.
"""

# plot box plot for duration for different hours of day
fig,ax = plt.subplots(figsize=(20,7))
# box plot using sns.boxplot x is 'trip_pickup_hour' and y is 'duration'
sns.boxplot(x = 'trip_pickup_hour', y='duration',data = trip_data,ax=ax)
ax.set_title('Box plot of trip_pickup hour with respect to trip duration')
sns.set()
plt.show()

"""Here again due to heavy outliers in duration data we are not able to observe the general graph. we might need to restrict our duration values to within 50min. """

# create restricted_duration dataframe with .loc on 'duration' column
restricted_duration= trip_data.loc[trip_data['duration']<50]
restricted_duration.shape

fig,ax = plt.subplots(figsize=(20,7))
sns.boxplot(x = 'trip_pickup_hour', y='duration',data = restricted_duration,ax=ax)
ax.set_title('Box plot of trip_pickup hour with respect to trip duration')
sns.set()
plt.show()

"""Early morning hours of 5AM to 6AM have shorter duration trips

Let's also explore duration with respect to top pickup location.
"""

# plot box plots of duration for top 10 frequent pickup locations
for top_pickup_locID in top_10_frequent_pickup_locations:
    # create the new dataframe for each location using .loc on 'PULocationID' - pickup_locID_dataframe
    pickup_locID_dataframe = trip_data.loc[trip_data['PULocationID'] == top_pickup_locID]
    # print the median duration for the top_pickup_locID
    print('The median trip duration of trips taken from '+str(top_pickup_locID)+' is '+str(pickup_locID_dataframe['duration'].median()))
    fig,ax = plt.subplots(figsize=(6,6))
    # sns.boxplot of duration from the dataframe pickup_locID_dataframe
    sns.boxplot(pickup_locID_dataframe['duration'],ax=ax)
    # set_title
    ax.set_title('box plot of duration for pickup location '+ str(top_pickup_locID))
    sns.set()
    plt.show()

"""Here again we can see for the most frequent pickup location 237 the duration value is less in comparison to other pickup locations, though 236 as well has lower duration amount close to 8 min. this might be the reason for less fare_amount as well.

## FINAL RESULTS FROM EDA -FEBRUARY

Following insights would be useful for our company's product launch in New York
* fare_amount  - most of the fare amount is within 10 dollar value as is shown by the median value. Though there are some significant outliers, the maximum of which is 6000 dollars.


* tip_amount - most of the tip amount is within 1-2 dollar as is shown by the median value. Though again here too we have outliers, the maximum of which is around 550 dollars. 


* duration - most of the values in duration is within 10 minutes range as is shown by the median value. We do have some outliers which are beyond the range of 3000 minutes.


* trip_distance - most of the trip_distance is within 1.6 miles value as is shown by the median. The outlier in this case is quite less.


* Credit card is the most preferred mode of payment followed by cash.


* Peak hour for the pick up and drop off is around evening from 5 to 8. The busiest time is 6PM.


* Weekdays except mondays have heavy taxi uses and among weekends Saturday has taxi uses more than on the  weekdays.


* The busiest location in terms of pickup and dropoff are 161, 236 and 237.


* Four of the busiest routes are - 264-264, 237-236, 236-236, 236-237


* Mostly 1 or 2 passenger avail the cab. Group rides are less common.


* From the hour 8PM to 5AM the median taxes seem to be a bit higher than other hours, it may be due to some overnight surcharges.


* Evening from 5PM to 7PM have quite variable taxes and is a bit higher than other times, it may be due to higher traffic charges.


* We discovered from the dataset that even for the busiest pickup location the median fare_amount is a bit lower than other busier pickup locations. So just choosing busy pickup locations for higher revenue won't work, we may have to choose locations taking into consideration both busy traffic and higher median fare_amount.


* Early morning hours of 5AM to 6AM have shorter duration trips

# **JULY 2020 - POST-COVID LOCKDOWN ANAYSIS**

We will do a same kind of analysis for the month of July also
"""

file_loc ='/content/drive/MyDrive/One_Learn_Data_Analytics_Module/taxi_data/yellow_tripdata_2020-07.csv'

# read file
trip_data2 = pd.read_csv(file_loc)
# print data shape
print(trip_data2.shape)
# print data head
trip_data2.head()

trip_data2.info()

"""DATA MANIPULATION BEFORE EDA"""

# remove following columns - 'VendorID','RatecodeID','store_and_fwd_flag'
trip_data2.drop(['VendorID','RatecodeID','store_and_fwd_flag'],axis=1,inplace=True)
# print data head
trip_data2.head()

# convert 'tpep_pickup_datetime' and 'tpep_dropoff_datetime' to datetime format
trip_data2['tpep_pickup_datetime'] = pd.to_datetime(trip_data2['tpep_pickup_datetime'])
trip_data2['tpep_dropoff_datetime'] = pd.to_datetime(trip_data2['tpep_dropoff_datetime'])
# print data info
print(trip_data2.info())
# print data head
trip_data2.head()

# create 'duration' column using pd.Timedelta(minutes=1)
trip_data2['duration'] = (trip_data2['tpep_dropoff_datetime'] - trip_data2['tpep_pickup_datetime'])/ pd.Timedelta(minutes=1)
# create 'trip_pickup_hour' column using 'tpep_pickup_datetime' column
trip_data2['trip_pickup_hour'] = trip_data2['tpep_pickup_datetime'].dt.hour
# create 'trip_dropoff_hour' column using 'tpep_dropoff_datetime' column
trip_data2['trip_dropoff_hour'] = trip_data2['tpep_dropoff_datetime'].dt.hour
# create 'trip_day' column using 'tpep_pickup_datetime' column - use day_name()
trip_data2['trip_day'] = trip_data2['tpep_pickup_datetime'].dt.day_name()
# print data info
print(trip_data2.info())
# print data head
trip_data2.head()

# print missing values for each column - use .isnull().sum
trip_data2.isnull().sum(axis=0).reset_index()

""" We can see that 'passenger_count' column and 'payment_type' columns has more than 62000 values out of total 800412 which is almost 8% of total data .therefore instead of removing these rows we are writing 'not_available' for the null values as removing these  can affect the quality of analysis in a negative way"""

#filling null values
trip_data2.fillna('Not_available',axis=1,inplace=True)

trip_data2.isnull().sum(axis=0).reset_index()

# value_counts for 'payment_type' column
trip_data2['payment_type'].value_counts()

# function for mapping numerical payment_type to actual payment
def map_payment_type(x):
    if x==1:
        return 'Credit_card'
    elif x==2:
        return 'Cash'
    elif x==3:
        return 'No_charge'
    elif x==4:
        return 'Dispute'
    elif x== 'Not_available':
      return 'not_available'
        #return 'Not_available'

# use .apply and lambda on payment_type column to change 'payment_type' column
trip_data2['payment_type'] = trip_data2.payment_type.apply(lambda x:map_payment_type(x))
# print data head
trip_data2.head(20)

#payment_type column is now a string type
trip_data2.info()

# create 'total_taxes' column from summing 'extra','mta_tax', 'improvement_surcharge'
trip_data2['total_taxes'] = trip_data2['extra']+trip_data2['mta_tax']+trip_data2['improvement_surcharge']
# drop 'extra','mta_tax','improvement_surcharge' columns
trip_data2.drop(['extra','mta_tax','improvement_surcharge'],axis=1,inplace=True)
# print data head
trip_data2.head()

# continuous_columns list
continuous_columns = ['fare_amount','tip_amount','total_taxes','total_amount','duration','trip_distance','tolls_amount']

trip_data2[continuous_columns].head()

# use .describe() for showing the statistics for continuous columns
trip_data2[continuous_columns].describe()

# import gridspec function from matplotlib
from matplotlib import gridspec

# for loop for continuous_columns variable
for feature in continuous_columns:
    # create a figure object using plt.figure
    fig = plt.figure(figsize=(14,7))
    # use gridspec.GridSpect with arguments nrows, ncols and figure to create areas for 2 plots in figure object
    gs = gridspec.GridSpec(nrows=1, ncols=2, figure=fig)
    # ax1 is first axes object created using fig.add_subplot(gs[0,0]) - controls the first area of figure object
    ax1 = fig.add_subplot(gs[0, 0])
    # histogram plot in first area using sns.distplot - attributes are kde and ax
    sns.distplot(trip_data2[feature],kde=True,ax=ax1)
    # using ax1.set_title to create title for histograms
    ax1.set_title('histogram of column values in '+feature)
    # ax2 is second axes object created using fig.add_subplot(gs[0,1]) - controls the second area of figure object
    ax2 = fig.add_subplot(gs[0,1])
    # box plot  in second area using sns.boxplot - attributes are ax
    sns.boxplot(trip_data2[feature],ax=ax2)
    # using ax2.set_title for box plot
    ax2.set_title('box plot of column values in '+feature)
    # seaborn style setting
    sns.set()
    # matplotlib command for displaying plots
    plt.show()

"""there seems to be negative values for pricing factors which does not make sense ,so we have to remove or change these. """

# using .loc to show negative values in fare_amount  # 
trip_data2.loc[trip_data2['fare_amount']<0]

# using .loc to show negative values in tip_amount
trip_data2.loc[trip_data2['tip_amount']<0]

# using .loc to show negative values in tolls_amount
trip_data2.loc[trip_data2['tolls_amount']<0]

# using .loc to show negative values in total_taxes
trip_data2.loc[trip_data2['total_taxes']<0]

# using .loc to show negative values in total_amount
trip_data2.loc[trip_data2['total_amount']<0]

"""Can i replace negative values of fare_amount with 0?

Ans. Not here. Because it will not give us a good measure of averages or other statistical measures.

From the above table displays it is clear whenever fare_amount is negative, we have negative values in 'tip_amount','total_taxes' and 'total_amount'. Negative values for these cases does not make sense for doing our analysis. The reason for these negative values can be explored later on if we want to understand the data more better. For now we will remove these rows.

Also, number of negative rows are 3710 which is 0.4% of total 800412 observations. So even if we remove them it does not hamper the quantity of data that we have.
"""

# data shape before filtering negative fare_amount rows
print(trip_data2.shape)
# using .loc to filter only those rows where fare_amount is positive 
trip_data2 = trip_data2.loc[trip_data2['fare_amount']>=0]
# print data shape
print(trip_data2.shape)
# print data.head()
trip_data2.head()

print(trip_data2.loc[trip_data2['tip_amount']<0].shape)
print(trip_data2.loc[trip_data2['total_taxes']<0].shape)

# using .loc to show negative values in duration
trip_data2.loc[trip_data2['duration']<0].shape

"""Since there are only two rows with negative duration, we will remove them so as to do our analysis in a better way"""

# using .loc to filter only those rows where duration is positive 
trip_data2 = trip_data2.loc[trip_data2['duration']>=0]
print(trip_data2.shape)

# import gridspec function from matplotlib
from matplotlib import gridspec
# plot box plot and histograms for continuous_columns variables
for feature in continuous_columns:
    fig = plt.figure(figsize=(14,7))
    gs = gridspec.GridSpec(nrows=1, ncols=2, figure=fig)
    ax1 = fig.add_subplot(gs[0, 0])
    sns.distplot(trip_data2[feature],kde=True,ax=ax1)
    ax1.set_title('histogram of column values in '+feature)
    ax2 = fig.add_subplot(gs[0,1])
    sns.boxplot(trip_data2[feature],ax=ax2)
    ax2.set_title('box plot of column values in '+feature)
    sns.set()
    plt.show()

# use .describe() again to show the statistics for these continuous variables
trip_data2[continuous_columns].describe()

"""Looking from the above histograms we can decipher following information for each column<br>

* fare_amount - most of the fare amount is within 10 dollar value as is shown by the median value. Though there are some significant outliers, the maximum of which is 1995 dollars.<br>
* tip_amount - most of the tip amount is within 1-1.7 dollar as is shown by the median value. Though again here too we have outliers, the maximum of which is around 1001 dollars.<br>
* tolls_amount - most of the tolls_amount value is 0 so it seems most of the trips do not have to pay for tolls.<br>
* total_taxes - most of the total_taxes values is within 1.3 dollars as is shown by the median value. Though we have outliers in this case but it is not as signiificant as the case for tip and fare.<br>
* total_amount - most of the total_amount values is within 14 dollars as is shown by the median value. Again the outliers in this case seems mostly because of outliers in fare_amount.<br>
* duration - most of the values in duration is within 10 minutes range as is shown by the median value. We do have some outliers which are beyond the range of 4000 minutes.<br>
* trip_distance - most of the trip_distance is within 1.8 miles value as is shown by the median. The outlier in this case is quite less.<br>
"""

# list of categorical_variables
categorical_variables = ['payment_type','trip_pickup_hour','trip_dropoff_hour','trip_day','PULocationID','DOLocationID']

# start exploration with payment_type using .value_counts()
trip_data2['payment_type'].value_counts()

# but this is a series for ease of plotting we need to use dataframe using .reset_index() on value_counts()
payment_type_category_count = trip_data2['payment_type'].value_counts().reset_index()
# print the above dataframe
payment_type_category_count

# we are shown the count under each category but it is better to have count% for comparison - create count_percent col
payment_type_category_count['count_percent'] = (payment_type_category_count['payment_type']/trip_data2.shape[0])*100
# print the data frame
payment_type_category_count

# now let's plot it as bar chart
# first step - create fig, ax object using plt.subplots
fig,ax = plt.subplots(figsize=(7,7))
# second step - use sns.barplot(x, y , data, ax) for plotting bar plot
sns.barplot(x = 'index', y = 'count_percent', data=payment_type_category_count,ax=ax)
# third step - use ax object to change plot properties - here we set a title with ax.set_title()
ax.set_title('box plot for payment_type column')
# third step - seaborn style setting
sns.set()
# fourth step - use plt.show() for showing the plots
plt.show()

"""From above we can understand that most of the payments are done through cash and credit cards. The proportion of credit card payments is around 60%.<br>
Now we look into time based categorical variables.<br>
* 'trip_pickup_hour'<br>
* 'trip_dropoff_hour'<br>
* 'trip_day'<br>
"""

# now let's plot all the time based categorical variables in this way using a for loop
for feature in ['trip_pickup_hour','trip_dropoff_hour','trip_day']:
    # Create a dataframe for the feature using value_counts().reset_index()
    feature_value_counts = trip_data2[feature].value_counts().reset_index()
    # create count_percent column 
    feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data2.shape[0])*100
    # print the number of categories in the feature
    print('Number of categories in feature '+ feature + ' is ' + str(feature_value_counts.shape[0]))
    # Create fig,ax object using plt.subplots 
    if feature_value_counts.shape[0]<10:
        fig,ax = plt.subplots(figsize=(7,7))
    else:
        fig,ax = plt.subplots(figsize=(20,7))
    # plot barplot x='index' and y='count_percent' using sns.barplot
    sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
    # set_title
    ax.set_title('Bar plot for '+ feature)
    # set_xlabel
    ax.set_xlabel(feature)
    sns.set()
    plt.show()

"""Based on above plots we can observe following things<br>
Trip Hour<br>
* the dropoff and pick up hour distribution looks almost same, it is because the trip duration in most of the cases is less than an hour with the median duration value as 10 min.<br>
* Peak hour for the pick up and drop off is from morning 11 am to evening 6pm. The busiest time is 2PM afternoon.<br>
* there is less traffic during night times and only after 8AM in morning does the pickup and drop off starts picking up pace.<br>

Trip day.
* Sunday has the lowest taxi uses.<br>
* Weekdays except Monday have heavy taxi uses.<br>
* Thursday and Wednesday has maximum taxi uses<br>
* weekends have lowest taxi uses  .<br>

Moving on we will explore the distribution of location based features:

'PULocationID'

'DOLocationID'
"""

# let's see the number of categories available in both pickup and dropoff location - PULocationID and DOLocationID
print(trip_data2['PULocationID'].value_counts().shape)
print(trip_data2['DOLocationID'].value_counts().shape)

for feature in ['PULocationID','DOLocationID']:
    # Create a dataframe for the feature using value_counts().reset_index()
    feature_value_counts = trip_data2[feature].value_counts().reset_index()
    # create count_percent column 
    feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data2.shape[0])*100
    # print the number of categories in the feature
    print('Number of categories in feature '+ feature + ' is ' + str(feature_value_counts.shape[0]))
    # Create fig,ax object using plt.subplots 
    fig,ax = plt.subplots(figsize=(25,7))
    # plot barplot x='index' and y='count_percent' using sns.barplot
    sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
    # set_title
    ax.set_title('Bar plot for '+ feature)
    # set_xlabel
    ax.set_xlabel(feature)
    sns.set()
    plt.show()

"""The above plots looks quite messy but one insight that we can indetify from above plot that most of pickup and dropoff points do not have more than 1% traffic (1.% percent of 800412 total trips is 8004.12).

So in our next plot we will filter out these pickup and dropoff points to look into the graph more clearly.
"""

for feature in ['PULocationID','DOLocationID']:
    feature_value_counts = trip_data2[feature].value_counts().reset_index()
    feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data2.shape[0])*100
    # filter only those location which has more than 1 % of traffic
    feature_value_counts = feature_value_counts.loc[feature_value_counts['count_percent']>=1]
    print('Number of categories in feature '+ feature + ' above 1 % count is ' + str(feature_value_counts.shape[0]))
    fig,ax = plt.subplots(figsize=(25,7))
    sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
    ax.set_title('Bar plot for '+ feature)
    ax.set_xlabel(feature)
    sns.set()
    plt.show()

"""From the above plots we can glance following insights<br>

The busiest location in terms of pickup are  236,237 and 186.<br>
The busiest location for dropoff too are 236 and 237.<br>

We can also look for routes which are busiest.<br>
For exploring busy routes we need to create a new route column which is a combination of pickup and dropoff point.<br>

So route = 'PULocationID'-'DULocationID'
"""

# create routes column using PULocationID and DOLocationID with lambda function
trip_data2['routes'] = trip_data2.apply(lambda x: str(x['PULocationID'])+'-'+str(x['DOLocationID']),axis=1)

# print the first five rows of routes data
trip_data2['routes'].head()

"""Now let's explore routes through the same bar plot code that we used for Location ID's. But in this case we will only look for routes with more than 0.25% counts (200103 trips)."""

# plot bar plot for routes which have trip count above 0.25%
feature = 'routes'
feature_value_counts = trip_data2[feature].value_counts().reset_index()
feature_value_counts['count_percent'] = (feature_value_counts[feature]/trip_data2.shape[0])*100
# choosing routes where the trip percent is above 0.25% of total trips
feature_value_counts = feature_value_counts.loc[feature_value_counts['count_percent']>=0.25]
print('Number of categories in feature '+ feature + ' above 0.25 % count is ' + str(feature_value_counts.shape[0]))
fig,ax = plt.subplots(figsize=(25,7))
sns.barplot(x='index',y='count_percent',data=feature_value_counts,ax=ax)
ax.set_title('Bar plot for '+ feature)
ax.set_xlabel(feature)
sns.set()
plt.show()

"""From the above plot we can observe that 5 busiest route are following:<br>
* 264-264
* 237-236
* 236-237
* 237-237
* 236-236

Finally we will look into the distribution of passenger_count
"""

# look into value_counts of 'passenger_count'
trip_data2['passenger_count'].value_counts()

"""Here we see that the mostly 1 or 2 passengers avail the cab. The instance of large group of people travelling together is rare.

**This is the result of some of the most important insights after doing univariate analysis:**
* fare_amount - most of the fare amount is within 10 dollar value as is shown by the median value. Though there are some significant outliers, the maximum of which is 1995 dollars.
* tip_amount - most of the tip amount is within 1-1.7 dollar as is shown by the median value. Though again here too we have outliers, the maximum of which is around 1001 dollars.
* duration - most of the values in duration is within 10 minutes range as is shown by the median value. We do have some outliers which are beyond the range of 4000 minutes.
* trip_distance - most of the trip_distance is within 1.8 miles value as is shown by the median. The outlier in this case is quite less.
* Credit card is the most preferred mode of payment followed by cash.
* Peak hour for the pick up and drop off is from 11am to 6 pm. The busiest time is 2PM.
* Weekdays except monday have heavy taxi uses ,thursday,wednesday has highest uses and weekends have the lowest uses for taxi.
* The busiest location in terms of pickup and dropoff are  236 , 237 and 186.
* Four of the busiest routes are - 264-264, 237-236, 236-237, 237-237
* Mostly 1 or 2 passenger avail the cab. Group rides are less common.

**BIVARIATE ANALYSIS**

Let's do a box plot of fair_amount with hour/day of trip to see how the fare changes for different hours of the day and for different days of the week
"""

# fig,ax object using plt.subplots()
fig,ax = plt.subplots(figsize=(25,7))
# box plot using - sns.boxplot(x, y , data, ax)
sns.boxplot(x = 'trip_pickup_hour',y='fare_amount',data=trip_data2,ax=ax)
# ax.set_title
ax.set_title('box plot of fare_amount wrt hour of the day')
# seaborn style setting
sns.set()
# matplotlib plt.show()
plt.show()

# fig,ax object using plt.subplots()
fig,ax = plt.subplots(figsize=(25,7))
# box plot using - sns.boxplot(x, y , data, ax)
sns.boxplot(x = 'trip_dropoff_hour',y='fare_amount',data=trip_data2,ax=ax)
# ax.set_title
ax.set_title('box plot of fare_amount wrt hour of the day')
# seaborn style setting
sns.set()
# matplotlib plt.show()
plt.show()

"""From the above plot we can observe that most of the outliers in fare happens during most hourse of the day except 2am to 4 am in the morning based on pickup time.<br>

Based on dropoff time, we have heavy outliers in the morning as well as evening.

For observing the distribution in a better way we would restrict the fare_amount to below 50 dollars( 5 times the median value)
"""

# restricted_fare_amount_data dataframe formation by filtering fare_amount less than 50 dollars
restricted_fare_amount_data = trip_data2.loc[(trip_data2['fare_amount']<=50) & (trip_data2['fare_amount']>=0)]
restricted_fare_amount_data.shape

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='fare_amount',data=restricted_fare_amount_data,ax=ax)
ax.set_title('box plot of fare_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='fare_amount',data=restricted_fare_amount_data,ax=ax)
ax.set_title('box plot of fare_amount wrt hour of the day')
sns.set()
plt.show()

"""We can see from the plots that trip pickup and dropoff hours  have much affect on median fare_amount from 12 am to 4 am in the early morning hours,this shows that either night charges are higher than day for taxi services the taxi rides are for long distances.

let's us see if hour of day has any effect on other pricing related variables or not.

Starting with total_amount
"""

fig,ax = plt.subplots(figsize=(25,7))
# sns.boxplot changes
sns.boxplot(x = 'trip_pickup_hour',y='total_amount',data=trip_data2,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
# sns.boxplot changes
sns.boxplot(x = 'trip_dropoff_hour',y='total_amount',data=trip_data2,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

"""Again here since we are plotting full range of total_amount our graph is able to show heavy outliers prominently but not the distribution of general cases.

So we will again build a dataframe for total_amount with restricted values less than 50 dollars
"""

# restricted_total_amount_data for filtering total_amount data to less than 50 dollars
restricted_total_amount_data = trip_data2.loc[trip_data2['total_amount']<=50]
restricted_total_amount_data.shape

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='total_amount',data=restricted_total_amount_data,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='total_amount',data=restricted_total_amount_data,ax=ax)
ax.set_title('box plot of total_amount wrt hour of the day')
sns.set()
plt.show()

"""Again we can see the median value increases after 11 pm and is high till 4 am in the morning ,so maybe night charges are mostly higher than day or taxi ride is longer .

We will explore tip_amount and total_taxes now. But for exploring them we will retrict the values for these variables to below 10 dollars because the median value for tip_amount was around 1-2 dollars while for total_taxes was around 0.8 dollars so if to see the general distribution clearly we are restricting it to a range of 5 times the median value.
"""

restricted_tip_amount_data = trip_data2.loc[trip_data2['tip_amount']<10]
restricted_total_taxes_data = trip_data2.loc[trip_data2['total_taxes']<10]

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='tip_amount',data=restricted_tip_amount_data,ax=ax)
ax.set_title('box plot of tip_amount wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='tip_amount',data=restricted_tip_amount_data,ax=ax)
ax.set_title('box plot of tip_amount wrt hour of the day')
sns.set()
plt.show()

"""Based on tip_amount plot we can see that tip amount declines after 11 pm till 5 am in the morning ,this is well explained because the same hours have high fare amount so customers pay tips rarely.

Let's observe total_taxes now
"""

# total_taxes = extra + improvement_surcharges + Mta

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_pickup_hour',y='total_taxes',data=restricted_total_taxes_data,ax=ax)
ax.set_title('box plot of total_taxes wrt hour of the day')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(25,7))
sns.boxplot(x = 'trip_dropoff_hour',y='total_taxes',data=restricted_total_taxes_data,ax=ax)
ax.set_title('box plot of total_taxes wrt hour of the day')
sns.set()
plt.show()

"""Now in this plot we can clearly observe that total_taxes change significantly with hour of the day. There are two patterns that we can observe here:

* from the hour 8PM to 11PM the median taxes seem to be a bit higher than other hours, it may be due to some overnight surcharges.
* Evening from 5PM to 6PM have quite variable taxes and is a bit higher than other times, it may be due to higher traffic charges.
* From 12 AM to 6 AM in the morning the taxes are very low as compared to other hours of the day ,this may be because of a promotional measure after covid unlockdown and also due to high fare amount at these hours

Overall the effect of hour of day is most clearly visible on total_taxes. we have two insights about how taxes change with hours:
* Overnight charges are applied between 8PM to 11PM
* Evening has higher variability in taxes and the taxes are usually high due to traffic probably.
* Taxes are very low fro m12 midnight to 6 AM in the morning.

**Let's move and explore the distribution of pricing variables with respect to day of week. For this analysis we will be using restricited version of dataset that we built for fare_amount, total_amount, tip_amount and total_taxes.**
"""

# plot of trip_day with fare_amount
fig,ax = plt.subplots(figsize=(7,7))
# changes in sns.boxplot x and y
sns.boxplot(x = 'trip_day',y='fare_amount',data=restricted_fare_amount_data,ax=ax)
ax.set_title('box plot of fare_amount wrt the day of the week')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(7,7))
sns.boxplot(x = 'trip_day',y='total_amount',data=restricted_total_amount_data,ax=ax)
ax.set_title('box plot of total_amount wrt the day of the week')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(7,7))
sns.boxplot(x = 'trip_day',y='tip_amount',data=restricted_tip_amount_data,ax=ax)
ax.set_title('box plot of tip_amount wrt the day of the week')
sns.set()
plt.show()

fig,ax = plt.subplots(figsize=(7,7))
sns.boxplot(x = 'trip_day',y='total_taxes',data=restricted_total_taxes_data,ax=ax)
ax.set_title('box plot of total_taxes wrt the day of the week')
sns.set()
plt.show()

"""We can see that pricing overall does not change much with respect to day of week.

*** PRICING VARIABLE EXPLORATION WITH LOCATION OF TRIP ***

Here we will look into the price changes for the most frequent trip pickup locations.
"""

# create a new series using value_counts() on 'PULocationID'
pickup_location_value_counts = trip_data2['PULocationID'].value_counts()
# show the series
pickup_location_value_counts.head()

# top 10 frequent pickup locations using .nlargest(10).index
top_10_frequent_pickup_locations = pickup_location_value_counts.nlargest(10).index
top_10_frequent_pickup_locations

# for loop for plotting box plot of each of the top 10 frequent pickup locations
for top_pickup_locID in top_10_frequent_pickup_locations:
    # create the new dataframe for each location using .loc on 'PULocationID' - pickup_locID_dataframe
    pickup_locID_dataframe = trip_data2.loc[trip_data2['PULocationID'] == top_pickup_locID]
    # print the median fare_amount for the top_pickup_locID
    print('The median fare_amount of trips taken from '+str(top_pickup_locID)+' is '+str(pickup_locID_dataframe['fare_amount'].median()))
    # fig,ax object
    fig,ax = plt.subplots(figsize=(6,6))
    # sns.boxplot of fare_amount from the dataframe pickup_locID_dataframe
    sns.boxplot(pickup_locID_dataframe['fare_amount'],ax=ax)
    # set_title
    ax.set_title('box plot of fare_amount for pickup location '+ str(top_pickup_locID))
    sns.set()
    plt.show()

"""So from above plot we can observe that for one of the most busiest pickup location median fare_amount is quite low in comparison to other busy locations. Though the outliers for pickup location 237 is high ,more than 600.

This could be helpful in adjusting our revenue expectation based on putting our cabs in a given location because just choosing busy pickup locations for higher revenue won't work, we may have to choose locations taking into consideration both busy traffic and higher median fare_amount.

**DURATION EXPLORATION**

Here we will explore the duration of trip exploration with pickup hour of day.
"""

# plot box plot for duration for different hours of day
fig,ax = plt.subplots(figsize=(20,7))
# box plot using sns.boxplot x is 'trip_pickup_hour' and y is 'duration'
sns.boxplot(x = 'trip_pickup_hour', y='duration',data = trip_data2,ax=ax)
ax.set_title('Box plot of trip_pickup hour with respect to trip duration')
sns.set()
plt.show()

"""Here again due to heavy outliers in duration data we are not able to observe the general graph. we might need to restrict our duration values to within 50min."""

# create restricted_duration dataframe with .loc on 'duration' column
restricted_duration= trip_data2.loc[trip_data2['duration']<50]
restricted_duration.shape

fig,ax = plt.subplots(figsize=(20,7))
sns.boxplot(x = 'trip_pickup_hour', y='duration',data = restricted_duration,ax=ax)
ax.set_title('Box plot of trip_pickup hour with respect to trip duration')
sns.set()
plt.show()

"""The duration starts rising after 11 PM and is high till 4AM in the morning which means trips are for longer distances relatively at these hours and this explains why fare amount was high at these hours

Let's also explore duration with respect to top pickup location.
"""

# plot box plots of duration for top 10 frequent pickup locations
for top_pickup_locID in top_10_frequent_pickup_locations:
    # create the new dataframe for each location using .loc on 'PULocationID' - pickup_locID_dataframe
    pickup_locID_dataframe = trip_data2.loc[trip_data2['PULocationID'] == top_pickup_locID]
    # print the median duration for the top_pickup_locID
    print('The median trip duration of trips taken from '+str(top_pickup_locID)+' is '+str(pickup_locID_dataframe['duration'].median()))
    fig,ax = plt.subplots(figsize=(6,6))
    # sns.boxplot of duration from the dataframe pickup_locID_dataframe
    sns.boxplot(pickup_locID_dataframe['duration'],ax=ax)
    # set_title
    ax.set_title('box plot of duration for pickup location '+ str(top_pickup_locID))
    sns.set()
    plt.show()

"""Here again we can see for the most frequent pickup location 237 the duration value is less in comparison to other pickup locations, also for locations 48 and 141 there is  lower duration amount close to 7 min.

## FINAL RESULTS FROM EDA -JULY 2020

**Following insights would be useful for our company's product launch in New York**<br>
* fare_amount - most of the fare amount is within 10 dollar value as is shown by the median value. Though there are some significant outliers, the maximum of which is 1995 dollars.
* tip_amount - most of the tip amount is within 1-1.7 dollar as is shown by the median value. Though again here too we have outliers, the maximum of which is around 1001 dollars.
* duration - most of the values in duration is within 10 minutes range as is shown by the median value. We do have some outliers which are beyond the range of 4000 minutes.
* trip_distance - most of the trip_distance is within 1.8 miles value as is shown by the median. The outlier in this case is quite less.
* Credit card is the most preferred mode of payment followed by cash.
* Peak hour for the pick up and drop off is around evening from 11AM to 6PM . The busiest time is 2PM.
* Weekdays except monday have heavy taxi uses, weekends have lowest uses and thursday-wednesday has highest taxi uses as compared to other weekdays.
* The busiest location in terms of pickup and dropoff are 186, 236 and 237.
* Four of the busiest routes are - 264-264, 237-236, 237-237, 236-237
* Mostly 1 or 2 passenger avail the cab. Group rides are less common.

* From the hour 8PM to 11PM the median taxes seem to be a bit higher than other hours, it may be due to some overnight surcharges AND taxes are low from 12 midnight to 4 AM in the morning.
* Evening from 5PM to 6PM have quite variable taxes and is a bit higher than other times, it may be due to higher traffic charges.
* We discovered from the dataset that even for the busiest pickup location the median fare_amount is a bit lower than other busier pickup locations. So just choosing busy pickup locations for higher revenue won't work, we may have to choose locations taking into consideration both busy traffic and higher median fare_amount.
* Early morning hours of 12AM to 4AM have longer duration trips

# **COMPARISON BETWEEN Februaury and July data anlaysis**

We have till now done the **EDA** on datasets showing New York taxi market data for **February 2020** (i.e. just before covid-19 lockdown) and data for **July** **2020** (i.e. just after covid-19 lockdown and taken out **few conclusive factors** from this analysis for each month.<br>
 These factors can now be used to compare the situation of N**ew York Taxi market for before and after covid-19 lockdown.**

## Following are the points based on which we will do the comparison between February and July data.<br>
* **Number of customers** - In February over 8 million people took taxis whereas in July only 10% of this i.e. around 800000 people took taxis ,this was due to many reasons such as work from home,disease apprehensions etc.

* **Fare amount** - For both Feb and July the median fare amount is around 10 dollars which means that most of the taxi users are using taxis for not so long distances .Among the outlier values, Maximum fare amount is over 6000 dollars  in February but its only 1995 dollars for July, showing that people were not moving very long distances due to covid precautions. 
* **Tip amount** - Median tip amount fell from around 2 dollars in Feb to around 1.6 dollars in July. This maybe simply because of less number of users.
* **Duration** - Most of the taxi rides ended within 10 minutes for both months ,maximum outlier is greater for July than in February but difference is not much for number of outliers.
* **Trip distance** - Median value for trip distance increased from 1.6 miles to 1.8 miles meaning that of all the people taking taxis in July most of them travelled longer distance than in Februaru,this is also due to the reason that July users number is 10 times less than in February.
* **Credit card** - For both months credit card is the most preferred payment type amongst users.
* **Peak hour** for pick-up and drop-off also changed for the months,earlier it was from 5 PM to 8PM in Feb which changed to 11AM to 6PM in July. The busiest hour was 6PM in February but in July it shifted to 2PM . This is showing that relatively more taxi users in July than February  are using taxis in the early part of the day,this is because in July most office goers were working from home and earlier due to them peak hours were in the evening as their work day ended then,now tha user base does not comprise of office people.
* **Weekdays** - other than Monday all weekdays had high taxi users in both months but in Feb , most taxi users were on Saturdays showing that people used to go around enjoying weekends but in July Saturday and Sunday both have lowest taxi users.
* **Location** -Busiest location in terms of pick-up and drop-off remained same  for 2 locations that is 236 and 237. the third busiest location_id was 161 in Feb but it changed to 186 in July meaning that user base has changed again verifying the reason of change in peak hours i.e. mainly offices were closed in July and people were working from home.
* **Routes** - Busiest routes (as taken path between pick-up and drop-off location ids ) remained same both in Feb and July although individual locations have changed for busiest.
* **Taxes** - Earlier high tax amount was from 8 PM to 5 AM ,it changed in July from 8PM to 11 PM only and lowest from 12 AM to 4AM as compared to other hours of the day. This decrease in taxes from midnight is due to low number of users in these hours.Traffic hours(shown by high variabilityin taxes) decreased from 5-7PM to 5-6PM  as lesser number of people are using taxis.

* We discovered from the dataset that even for the busiest pickup location the median fare_amount is a bit lower than other busier pickup locations. So just choosing busy pickup locations for higher revenue won't work, we may have to choose locations taking into consideration both busy traffic and higher median fare_amount.

# **Conclusion**
* Loooking at the customers side i.e. the  **DEMAND**  side ,the reason for sharp decrease in the users base for taxis from February to July is mostly due to office going population.This is evident from multiple facotrs like change in peak hours of taxi users and change in busiest pickup and drop-off locations.Therefore covid-19 lockdown has affected the demand for Taxi Services **negatively** in New York Taxi market.

* From the **Company's** perspective the important factors to focus on are :<BR>
 - **Busiest location ids and busiest routes** must be focused more,measures such as maintaining an optimum number of drivers in these locations should be a priority and in the locations where demand is low ,the drivers should also be minimum. This will save a significant cost for the company such as communicating with the drivers,connecting users with drivers etc.
  - **Peak hours ** are another important factor for the company.Charging higher fare amounts in these hours is easy as user demand is high ,and to maintain edge over other competitve companies our company can give discount to users opting to pay with** credit cards**.Most people like to pay using credit cards we have seen this in our anaysis,so having a tie up with credit companies will attract more profits for the company as well as increase their user base.

* For **Future course** of action we have to ensure that in case another lockdown happens in future the number of taxi users shall not go down drastically like July 2020,for this we need taxi users to believe that cars we provide are safe from covid-19,one step can be sanitized cars and vaccinated drivers.
"""

